import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
from scipy.sparse import issparse

class TuringPatternHunter:
    def __init__(self, adata, bin_size=20, device=None):
        """
        PyTorch-accelerated Turing Pattern Hunter
        """
        self.adata = adata
        self.bin_size = bin_size
        
        # 1. è‡ªåŠ¨æ£€æµ‹è®¡ç®—è®¾å¤‡
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
            
        # 2. è·å–ç‰©ç†åæ ‡èŒƒå›´
        if 'spatial' not in self.adata.obsm:
            raise ValueError("adata.obsm['spatial'] not found!")
            
        coords = self.adata.obsm['spatial']
        self.x_min, self.y_min = coords.min(axis=0)
        self.x_max, self.y_max = coords.max(axis=0)
        
        # 3. è®¡ç®—ç½‘æ ¼å°ºå¯¸
        self.img_width = int(np.ceil((self.x_max - self.x_min) / bin_size))
        self.img_height = int(np.ceil((self.y_max - self.y_min) / bin_size))
        
        print(f"åˆå§‹åŒ–çŒäºº (PyTorchç‰ˆ):")
        print(f"  - ç‰©ç†èŒƒå›´: X[{self.x_min:.1f}, {self.x_max:.1f}], Y[{self.y_min:.1f}, {self.y_max:.1f}]")
        print(f"  - Bin Size: {bin_size} (å¾®ç±³/åƒç´ )")
        print(f"  - ç”Ÿæˆå›¾åƒå°ºå¯¸: {self.img_height} x {self.img_width} åƒç´ ")
        print(f"  - è®¡ç®—è®¾å¤‡: {self.device}")

        # 4. é¢„è®¡ç®—åæ ‡ç´¢å¼• (N_cells,)
        x_idx = ((coords[:, 0] - self.x_min) / self.bin_size).astype(int)
        y_idx = ((coords[:, 1] - self.y_min) / self.bin_size).astype(int)
        
        # è¾¹ç•Œä¿æŠ¤
        x_idx = np.clip(x_idx, 0, self.img_width - 1)
        y_idx = np.clip(y_idx, 0, self.img_height - 1)
        
        # è½¬ä¸º Tensor å¹¶ç¼“å­˜
        self.indices = torch.tensor(np.stack([y_idx, x_idx]), device=self.device)
        self.flat_indices = self.indices[0] * self.img_width + self.indices[1]

    def _get_gene_image_tensor(self, gene_names_or_indices):
        """
        å†…éƒ¨è¾…åŠ©ï¼šå°†åŸºå› è¡¨è¾¾é‡è½¬ä¸º GPU ä¸Šçš„ Tensor å›¾åƒ
        (å·²ä¿®å¤ç»´åº¦åŒ¹é…å’Œ range æ”¯æŒé—®é¢˜)
        """
        # åˆ¤æ–­è¾“å…¥æ˜¯å¦ä¸ºæ‰¹é‡ (å¢åŠ å¯¹ range çš„æ”¯æŒ)
        is_batch = isinstance(gene_names_or_indices, (list, tuple, np.ndarray, pd.Index, range))
        
        if not is_batch:
            gene_list = [gene_names_or_indices]
        else:
            gene_list = gene_names_or_indices

        # A. è·å–åˆ—ç´¢å¼•
        # å¦‚æœä¼ å…¥çš„æ˜¯ range æˆ–æ•´æ•°åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
        if isinstance(gene_list, range) or (len(gene_list) > 0 and isinstance(gene_list[0], (int, np.integer))):
            idxs = gene_list
        else:
            # å¦‚æœæ˜¯åŸºå› åï¼Œè½¬æ¢ä¸ºç´¢å¼•
            idxs = self.adata.var_names.get_indexer(gene_list)

        # B. æå–è¡¨è¾¾é‡çŸ©é˜µ (N_cells, Batch)
        # ä¼˜å…ˆæ£€æŸ¥ raw
        if self.adata.raw is not None:
             X_data = self.adata.raw.X[:, idxs]
        else:
             X_data = self.adata.X[:, idxs]

        if issparse(X_data):
            X_data = X_data.toarray()
            
        # C. è½¬ä¸º Tensor
        values = torch.tensor(X_data, dtype=torch.float32, device=self.device) 
        
        # --- ğŸ›¡ï¸ ç»´åº¦é˜²å¾¡é€»è¾‘ (å…³é”®ä¿®å¤) ---
        expected_cells = self.indices.shape[1]
        
        # Case 1: å˜æˆ 1D (N_cells,) -> å‡ç»´åˆ° (N_cells, 1)
        if values.ndim == 1:
            values = values.unsqueeze(1)
            
        # Case 2: ç»´åº¦è½¬ç½® (Batch, N_cells) -> (N_cells, Batch)
        if values.shape[0] != expected_cells and values.shape[1] == expected_cells:
             values = values.T

        # Case 3: å½¢çŠ¶ä¾ç„¶ä¸å¯¹ (Crashä¿æŠ¤)
        if values.shape[0] != expected_cells:
             # å¦‚æœåªæœ‰ 1 è¡Œä½†éœ€è¦ N è¡Œ (å¹¿æ’­)
             if values.shape[0] == 1:
                 values = values.repeat(expected_cells, 1)
             else:
                 raise RuntimeError(f"Shape Mismatch! Expected {expected_cells} cells, got {values.shape}. Check adata.X integrity.")

        batch_size = values.shape[1]
        
        # D. æ …æ ¼åŒ– (Scatter Add)
        img_sum = torch.zeros((batch_size, self.img_height * self.img_width), device=self.device)
        
        # values ç°åœ¨å¿…é¡»æ˜¯ (N_cells, Batch)ï¼Œæˆ‘ä»¬éœ€è¦å®ƒçš„è½¬ç½® (Batch, N_cells) æ¥åš index_add_
        img_sum.index_add_(1, self.flat_indices, values.T)
        
        # E. è®¡ç®—å¹³å‡å€¼ (Sum / Count)
        ones = torch.ones(values.shape[0], device=self.device)
        count_map_flat = torch.zeros(self.img_height * self.img_width, device=self.device)
        count_map_flat.index_add_(0, self.flat_indices, ones)
        
        img_sum = img_sum / (count_map_flat.unsqueeze(0) + 1e-8) 
        
        # F. Reshape & Log1p
        imgs = img_sum.view(batch_size, self.img_height, self.img_width)
        imgs = torch.log1p(imgs)
        
        # å¦‚æœè¾“å…¥æ˜¯å•ä¸ªåŸºå› ï¼Œé™ç»´è¿”å›
        if not is_batch and imgs.shape[0] == 1:
            return imgs.squeeze(0)
            
        return imgs

    def _create_gaussian_kernel(self, sigma, truncate=4.0):
        """åˆ›å»º PyTorch é«˜æ–¯å·ç§¯æ ¸"""
        radius = int(truncate * sigma + 0.5)
        k_size = 2 * radius + 1
        
        x = torch.arange(-radius, radius + 1, dtype=torch.float32, device=self.device)
        y = torch.arange(-radius, radius + 1, dtype=torch.float32, device=self.device)
        xx, yy = torch.meshgrid(x, y, indexing='xy')
        kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))
        kernel = kernel / kernel.sum()
        
        return kernel.view(1, 1, k_size, k_size), radius

    def screen_geometry(self, sigma_inner=2, sigma_outer=5, top_n=50, batch_size=100):
        """
        L1: GPU å¹¶è¡Œ DoG æ‰«æ
        """
        print(f">>> L1: æ­£åœ¨æ‰«æ {self.adata.n_vars} ä¸ªåŸºå›  (GPUåŠ é€Ÿ)...")
        results = []
        genes = self.adata.var_names
        n_genes = len(genes)
        
        # å‡†å¤‡å·ç§¯æ ¸
        k_smooth, pad_smooth = self._create_gaussian_kernel(0.5)
        k_in, pad_in = self._create_gaussian_kernel(sigma_inner)
        k_out, pad_out = self._create_gaussian_kernel(sigma_outer)

        # æ‰¹é‡å¤„ç†
        for i in range(0, n_genes, batch_size):
            end = min(i + batch_size, n_genes)
            batch_genes = genes[i:end]
            
            # 1. è·å–å›¾ç‰‡ (ä½¿ç”¨ä¿®å¤åçš„å‡½æ•°ï¼Œæ”¯æŒ range)
            imgs = self._get_gene_image_tensor(range(i, end)) 
            imgs = imgs.unsqueeze(1) # (B, 1, H, W)
            
            # 2. å·ç§¯è®¡ç®—
            imgs_smooth = F.conv2d(imgs, k_smooth, padding=pad_smooth)
            g_in = F.conv2d(imgs_smooth, k_in, padding=pad_in)
            g_out = F.conv2d(imgs_smooth, k_out, padding=pad_out)
            dog = g_in - g_out
            
            # 3. è®¡ç®—åˆ†æ•°
            dog_flat = dog.view(dog.shape[0], -1)
            peak_scores = torch.quantile(dog_flat, 0.999, dim=1).cpu().numpy()
            trough_scores = torch.quantile(dog_flat, 0.001, dim=1).cpu().numpy()
            
            for idx, gene in enumerate(batch_genes):
                results.append({
                    'gene': gene,
                    'peak_score': peak_scores[idx],
                    'trough_score': trough_scores[idx]
                })
                
            if i % 1000 == 0:
                print(f"    å·²å¤„ç† {end}/{n_genes}...", end="\r")

        print(f"\nç­›é€‰å®Œæˆã€‚")
        df = pd.DataFrame(results)
        self.candidates_u = df.nlargest(top_n, 'peak_score')
        self.candidates_v = df.nsmallest(top_n, 'trough_score')
        return self.candidates_u, self.candidates_v

    def _get_scale_torch(self, img_tensor):
        """è®¡ç®—ç‰¹å¾å°ºåº¦ (Autocorrelation decay)"""
        h, w = img_tensor.shape
        crop_size = min(h, w, 200)
        cy, cx = h//2, w//2
        img_crop = img_tensor[cy-crop_size//2 : cy+crop_size//2, cx-crop_size//2 : cx+crop_size//2]
        
        img_crop = img_crop - img_crop.mean()
        
        H, W = img_crop.shape
        padded = F.pad(img_crop, (0, W, 0, H))
        
        fft_img = torch.fft.rfft2(padded)
        fft_corr = fft_img * torch.conj(fft_img)
        corr_map = torch.fft.irfft2(fft_corr)
        
        profile = corr_map[0, :min(H, W)//2]
        profile = profile / (profile.max() + 1e-9)
        
        idxs = torch.where(profile < 0.5)[0]
        if len(idxs) > 0:
            return idxs[0].item()
        return len(profile)

    def pair_and_validate(self):
        """
        L2/L3: é…å¯¹ä¸ç‰©ç†æ ¡éªŒ
        """
        print(">>> L2/L3: é…å¯¹ä¸ç‰©ç†æ ¡éªŒ (GPUåŠ é€Ÿ)...")
        pairs = []
        
        unique_genes = list(set(self.candidates_u['gene']) | set(self.candidates_v['gene']))
        gene_cache = {} 
        
        print(f"    é¢„è®¡ç®— {len(unique_genes)} ä¸ªå€™é€‰åŸºå› çš„ç‰¹å¾...")
        batch_size = 50
        for i in range(0, len(unique_genes), batch_size):
            batch_g = unique_genes[i : i+batch_size]
            imgs = self._get_gene_image_tensor(batch_g)
            
            for j, g in enumerate(batch_g):
                # å¦‚æœ batch_size=1, imgs å¯èƒ½åªæœ‰ (H, W)ï¼Œéœ€è¦å…¼å®¹
                if imgs.ndim == 2: img = imgs
                else: img = imgs[j]
                
                scale = self._get_scale_torch(img)
                gene_cache[g] = {'img': img, 'scale': scale}

        u_genes = self.candidates_u['gene'].values
        v_genes = self.candidates_v['gene'].values
        
        for u_gene in u_genes:
            cache_u = gene_cache[u_gene]
            img_u = cache_u['img']
            scale_u = cache_u['scale']
            
            for v_gene in v_genes:
                if u_gene == v_gene: continue
                
                cache_v = gene_cache[v_gene]
                img_v = cache_v['img']
                scale_v = cache_v['scale']
                
                mask = (img_u > 0.1) | (img_v > 0.1)
                if mask.sum() < 50: continue
                
                val_u = img_u[mask]
                val_v = img_v[mask]
                
                mean_u = val_u.mean()
                mean_v = val_v.mean()
                num = ((val_u - mean_u) * (val_v - mean_v)).sum()
                den = torch.sqrt(((val_u - mean_u)**2).sum() * ((val_v - mean_v)**2).sum())
                corr = (num / (den + 1e-8)).item()
                
                if corr > 0: continue 
                if scale_v <= scale_u: continue
                
                ratio = scale_v / (scale_u + 1e-6)
                
                pairs.append({
                    'U_gene': u_gene,
                    'V_gene': v_gene,
                    'correlation': corr,
                    'scale_ratio': ratio,
                    'Turing_Score': ratio * abs(corr)
                })
        
        results_df = pd.DataFrame(pairs)
        if results_df.empty:
            return pd.DataFrame(columns=['U_gene', 'V_gene', 'correlation', 'scale_ratio', 'Turing_Score'])
            
        results_df = results_df.sort_values('Turing_Score', ascending=False)
        return results_df